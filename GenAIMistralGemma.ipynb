{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAfrHF4y04u0IoIx4GU3v7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balachandar-Ganesan/GraphRAG/blob/main/GenAIMistralGemma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index.llms.mistralai\n",
        "!pip install llama-index-core\n",
        "!pip install llama-index-llms-openai\n",
        "!pip install llama-index-llms-replicate\n",
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "id": "CoTZDIuXgeq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MISTRAL_API_KEY\"] = \"Enter Mistral Key Here\"\n",
        "\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "\n",
        "llm = MistralAI(model=\"codestral-latest\", temperature=0.1)"
      ],
      "metadata": {
        "id": "94j1Oy9Fgl-W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "def getCode(strContent):\n",
        "  messages = [ChatMessage(role=\"user\", content=strContent)]\n",
        "\n",
        "  response = llm.chat(messages)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "EmGE5xXbg6Jb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "strContent =\"\"\"\n",
        "I have a table in SQL.\n",
        "It has columns Runs,Innings and MatchDate.\n",
        "Write a query to get runs scored during First Innings every year\n",
        "\"\"\"\n",
        "print(getCode(strContent))"
      ],
      "metadata": {
        "id": "vA_IXQt5joa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strContent =\"\"\"\n",
        "Write a Code in Python for Email Validation\n",
        "using regex and Decorators\n",
        "\"\"\"\n",
        "print(getCode(strContent))"
      ],
      "metadata": {
        "id": "Tnju3Cy5jzmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strContent =\"\"\"\n",
        "I have a table in PowerBI.\n",
        "It has two columns Price and SellDate.\n",
        "How to compute Aroon Indicator for Price column\n",
        "\"\"\"\n",
        "print(getCode(strContent))"
      ],
      "metadata": {
        "id": "0a3ucRPwj8cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strContent =\"\"\"\n",
        "I have a table in Qlikview.\n",
        "It has two columns Price and SellDate.\n",
        "How to compute YTD for the price column\n",
        "\"\"\"\n",
        "print(getCode(strContent))"
      ],
      "metadata": {
        "id": "gjfI6Ip6kMMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strContent =\"\"\"\n",
        "I have the data of local train movement in Mumbai with traincode,starttime,startlocation,endlocation.\n",
        "Want to create animation to display passenger movement using map control\n",
        "Explain steps needed\n",
        "\"\"\"\n",
        "print(getCode(strContent))"
      ],
      "metadata": {
        "id": "s0YL4CrXkVoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch accelerate"
      ],
      "metadata": {
        "id": "6tef2JkTUsmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "try:\n",
        "        from google.colab import userdata\n",
        "        hf_token = userdata.get(\"HF_TOKEN\")\n",
        "        login(token=hf_token)\n",
        "        print(\"Successfully logged in to Hugging Face Hub.\")\n",
        "except Exception as e:\n",
        "        print(f\"Error logging in to Hugging Face Hub: {e}\")\n",
        "        print(\"Ensure 'HF_TOKEN' is set as a secret in Colab and 'Notebook access' is enabled.\")"
      ],
      "metadata": {
        "id": "uR8dxd3fUu3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HF_TOKEN'] = \"\""
      ],
      "metadata": {
        "id": "DTC87r13Uzft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\")"
      ],
      "metadata": {
        "id": "XsHLtC2WU1dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Write  a Function in Python to implement XORSHIFT in a way I can explain.\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "0_8LST2FU5TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**input_ids, max_new_tokens=1024)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "id": "N5rScl90U7Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"How to select 5 to 10 random records from a table using SQL\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**input_ids, max_new_tokens=1024)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ],
      "metadata": {
        "id": "rMO4xGidVBFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "zN0JXavKVFYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"google/gemma-2-2b-it\",\n",
        "        model_kwargs={\"torch_dtype\": torch.bfloat16}, # Use bfloat16 for memory efficiency\n",
        "        device=\"cpu\", # or \"mps\" for Mac, or None for CPU\n",
        "    )"
      ],
      "metadata": {
        "id": "tG5V1lJsVHvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " messages = [\n",
        "        {\"role\": \"user\", \"content\": \"I have table in SQL. There are two columns Innings and Runs. Write a Query to get Sum of Runs scored in First Innings\"},\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(messages, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "mCeITIsFVLDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}