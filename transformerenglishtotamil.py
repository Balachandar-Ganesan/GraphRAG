# -*- coding: utf-8 -*-
"""TransformerEnglishToTamil.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gLzsmGP99QgolRS_dAj-U_zm2eHILo1z
"""



#install transformers library
!pip install transformers -U -q

# install sentencepiece library
!pip install sentencepiece



from transformers import MBartForConditionalGeneration, MBart50TokenizerFast
from transformers.optimization import AdamW
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"


print('Model loading started')
model = MBartForConditionalGeneration.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")
tokenizer = MBart50TokenizerFast.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="en_XX", tgt_lang="ta_IN")
print('Model loading done')



#src_text = "state with the second"
#tgt_text = "இரண்டாவது மாநிலம்  "

#src_text = "to Tamil Nadu"
#tgt_text = "தமிழ்நாட்டிடம் "


src_text = "in India"
tgt_text = "இந்தியாவின்   "




model_inputs = tokenizer(src_text, return_tensors="pt")
with tokenizer.as_target_tokenizer():
    labels = tokenizer(tgt_text, return_tensors="pt").input_ids

# Set up the optimizer and training settings
optimizer = AdamW(model.parameters(), lr=1e-4)
model.train()

print('Fine-tuning started')
for i in range(1):
 optimizer.zero_grad()
 output = model(**model_inputs, labels=labels) # forward pass
 loss = output.loss
 loss.backward()
 optimizer.step()
print('Fine-tuning ended')

# input sentences
input_text = ["Andhra Pradesh may soon lose its position as the state with the second longest coastline in India to Tamil Nadu."]


# convert sentences to tensors
model_inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True)

# translate from English to Tamil
generated_tokens = model.generate(
    **model_inputs,
    forced_bos_token_id=tokenizer.lang_code_to_id["ta_IN"]
)

translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)

print(translation)