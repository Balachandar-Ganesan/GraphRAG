{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBfWrNi3cbAQ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sxOKWYnAmQH",
        "outputId": "4d6f99c0-1b6f-4bb2-f755-b98d495e0648",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "#install transformers library\n",
        "!pip install transformers -U -q\n",
        "\n",
        "# install sentencepiece library\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URjAJlZ6vWzs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_JKlNHtxOAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1070175c-0ac6-4131-f2b5-932398b4d133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loading started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loading done\n"
          ]
        }
      ],
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from transformers.optimization import AdamW\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "print('Model loading started')\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"en_XX\", tgt_lang=\"ta_IN\")\n",
        "print('Model loading done')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjrmKXAk8GEU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYI0mBpoxtQc",
        "outputId": "06f44d9f-faed-490f-9672-bfd47e6c2514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning started\n",
            "Fine-tuning ended\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#src_text = \"state with the second\"\n",
        "#tgt_text = \"இரண்டாவது மாநிலம்  \"\n",
        "\n",
        "#src_text = \"to Tamil Nadu\"\n",
        "#tgt_text = \"தமிழ்நாட்டிடம் \"\n",
        "\n",
        "\n",
        "src_text = \"in India\"\n",
        "tgt_text = \"இந்தியாவின்   \"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_inputs = tokenizer(src_text, return_tensors=\"pt\")\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(tgt_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Set up the optimizer and training settings\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "model.train()\n",
        "\n",
        "print('Fine-tuning started')\n",
        "for i in range(1):\n",
        " optimizer.zero_grad()\n",
        " output = model(**model_inputs, labels=labels) # forward pass\n",
        " loss = output.loss\n",
        " loss.backward()\n",
        " optimizer.step()\n",
        "print('Fine-tuning ended')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMC5iXc3xofo",
        "outputId": "65477cc9-4dec-47d5-eb75-a541dd7803b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['தமிழ்நாட்டிடம் இந்தியாவின் இரண்டாவது நீண்ட கடலோர மாநிலம் ஆந்திரப் பிரதேசம் விரைவில் தனது இடத்தை இழந்துவிடும்.']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# input sentences\n",
        "input_text = [\"Andhra Pradesh may soon lose its position as the state with the second longest coastline in India to Tamil Nadu.\"]\n",
        "\n",
        "\n",
        "# convert sentences to tensors\n",
        "model_inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# translate from English to Tamil\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"ta_IN\"]\n",
        ")\n",
        "\n",
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "print(translation)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}